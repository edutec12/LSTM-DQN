# LSTM-DQN

This script implements two models for predicting the next values in a given sequence using Python. The length of subsequences used for training and testing is defined by "seq_length", and the sequence is defined in the "raw_seq" list at the beginning of the script.

The first model is a simple LSTM neural network that is trained using the Keras library. The training data is prepared by dividing the sequence into subsequences of length "seq_length" and their corresponding next values. The LSTM requires a 3D array of shape (samples, timesteps, features), so these subsequences are reshaped to be compatible with the input format of the LSTM. The model is then fit to this data for a specified number of epochs, and the loss is plotted over time. Finally, the model is used to predict the next 10 values in the sequence, and the predicted values and mean squared error are printed and plotted.

The second model is a Deep Q-Network (DQN) that employs a Q-learning algorithm. The implementation uses a deque to store the experience replay memory, and a target network is used to update the Q-value estimates. The state representation is defined as the index of the previous "seq_length" values in the sequence concatenated with the index of the current action. The reward function is defined as the absolute difference between the predicted and actual next values in the sequence. The model is trained over a specified number of epochs, and the current and cumulative reward are printed for each epoch. Finally, the model is used to predict the next 10 values in the sequence, and the predicted values and mean squared error are printed and plotted.
